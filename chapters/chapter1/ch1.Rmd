---
title: "mdmb_ch1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Chapter 1 - Generative Models for Discrete Data

#Section 1.1 Objectives

Actions of counting permeate biology and often consider the following questions:  
- How **much**?  
- How **often**?  
- How **many**?  

The results of interrigating these questions result in *discrete* variables, they are quantized, not continuous.  

This chapter considers a **top down** approach to understanding the outcome of events, or *probabilities*. These probabilities differ based on the model on which these outcomes occur.  

# Section 1.2 HIV mutation rate  

Given a mutation rate of 5x10^-4 nt per replication cycle, then the rate of mutations along the HIV genome of about 10,000 nt will follow a Poisson distribution with a rate of 5. The standard error will be 5^1/2

The *Poisson* distribution can be thought of as the rate of occurances happening along a streamline. For example, Poisson distributions can be used to model the probability of hitting potholes as you drive along a street of a given length.  

The Poisson distribution can also allow us to understand the probability of seeing other events, for example 3 or even 100.

This can be done by taking the value of the *rate parameter*, noted by lambda.  

```{r}
dpois(x=3, lambda=5)
```
```{r}
dpois(x=100, lambda=5)
```

As you an see, 3 mutations occuring in a replication cycle has a 14% probability given the Poisson distribution, but 100 (20x more than lambda) has almost a one in megasuperduperkabillion chance of ever happening.  


The distribution of probabilities between 0 and 12 mutations gives us a better idea of the probability distribution of this event.

```{r}
hivpois <- dpois(x=0:12, lambda=5)
hivpois
```

And visualizing that:

```{r}
barplot(hivpois, names.arg = 0:12, col = "skyblue")
```

The Poisson probability of seeing x can be defined by the formula:  

  (e^-lambda x lambda^x) / x!  

but dpois() is easier to write.

Other distributions used for describing discrete events include the: Bernoulli, binomial, and multinomial distributions.  

# 1.3 Exploring discrete probability models

Mutations can also be thought of through a binary model: yes or no, mutation or not, these are known as the *levels* of the categorical variable.

Different variables can have different levels, diploid genotypes have three: AA, Aa, and aa.  

Codons have 64 levels...  

If the order of data observed doesn't matter, then the random variable is called *exchangeable*. If this is the case, then the only measurement that matters if count, not order. 

# 1.3.1 Bernoulli

A simple Bernoulli trial is a two-outcome coin flip: **heads** and **tails**. It is modelled using a Bernoulli random variable.  

To generate a single binomial trial of 15 fair coin tosses:  

```{r}
rbinom(15, prob =0.5, size =1)
```

#1.3.2 Success or failure?

If we only care about the counts and not the order (remember exchangable variables?) then we can change the function call:  

```{r}
rbinom(1, prob = .7, size =12)
```

This result gives us the number of successes, in this case the number of times a ball fell into a larger right box compared to a smaller left one.  

These kind of models can be see throughout biology: CpG or non-CpG, pyrimidine or purine, diseased or health, allele A or a. This works because the complimentary of p is just q = 1-p.  

The number of successes in n Bernoulli trials with a given probability of success of pis a binomial random variable that follows a B(n,p) distribution.

If x is 15 and the probability is 0.3, then a *probability mass distribution* can be found with the following:  

```{r}
probs = dbinom(0:15, prob=0.3, size=15)
round(probs, 2)
```
and visualizing it:  

```{r}
barplot(probs, names.arg = 0:15, col = "slateblue")
```

Thus, X distributed as a binomial distribution with parameters (n = trial count, p = probability) is X ~ B(n,p).  

Further, the probability of seeing X = k successes is:  

P(X=k) = (n k) p^k x (1-p)^(n-k)

QUESTION: TO DO LATER
What is the out put for k=3, p=.667, n=4?  

# 1.3.3 Fishies

The Poisson distribution can overtake the binomial distribution if p is small and n is large. The rate parameter of a Poisson distribution is:  

lambda = np  

For a Poisson distribution:

P(X=k) = (lambda^k x e^-lambda) / k!

To find P(X=3):  

```{r}
(5^3 * exp(-5))/factorial(3)
```
Note: this is the same answer as: 

dpois(x=3, lambda=5)  

Let's simulate mutations along an HIV genome.

```{r}
rbinom(1, prob=5e-4, size=10000)
```
```{r}
simu = rbinom(n=300000, prob=5e-4,size=10000)
barplot(table(simu), col="lavender")
```

#1.3.4 Applying these principles to epitope detection.

For conducting an ELISA assay there are known errors involved with:  

- baseline noise level/false positive rate of 0.01, this can be defined as P(declare epitope | no epitope)
- the protein is tested at 100 independent and different positions
- a data collection from a patient is 50 samples

So p = 0.01, n = 50, and lambda = 0.5.

```{r}
simu1 = rbinom(n=50, prob=0.01,size=100)
barplot(table(simu), col="lavender")
```

```{r}
dpois(100, 0.01)
simu2 = rpois(n=50, lambda=0.05)
barplot(table(simu), col="lavender")
```

```{r}
data1 <- load("data/e100.RData")
barplot(e100, ylim = c(0, 7), width = 0.7, xlim = c(-0.5, 100.5),
  names.arg = seq(along = e100), col ="forestgreen")
```

